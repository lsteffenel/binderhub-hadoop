{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Initial definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HADOOP_VERSION=2.9.2\n",
      "env: HADOOP_PATH=hadoop-2.9.2\n"
     ]
    }
   ],
   "source": [
    "%env HADOOP_VERSION     2.9.2\n",
    "%env HADOOP_PATH hadoop-2.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Downloading Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://ftp.unicamp.br/pub/apache/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz -q --show-progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Extracting compressed files and removing .tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'hadoop-2.9.2': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm ${HADOOP_PATH} -r\n",
    "!tar -xvf hadoop-${HADOOP_VERSION}.tar.gz >/dev/null \n",
    "# !rm       hadoop-${HADOOP_VERSION}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Discovering the Java path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/jvm/java-8-openjdk-amd64\n"
     ]
    }
   ],
   "source": [
    "!dirname $(dirname $(readlink -f $(which javac)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Java path envvar\n",
    "\n",
    "We also added it to user's .bashrc so it will be loaded as the nodes perform ssh connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ~/.bashrc\n",
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ~/.profile\n",
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ${HADOOP_PATH}/etc/hadoop/hadoop-env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Hadoop in Standalone Mode (local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## MapReduce in the local filesystem - word count example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/07/07 17:38:14 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "19/07/07 17:38:14 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/home/matheus/local-home/git/github/binderhub-hadoop/output already exists\n",
      "\tat org.apache.hadoop.mapreduce.lib.output.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:146)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:279)\n",
      "\tat org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:145)\n",
      "\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)\n",
      "\tat org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1893)\n",
      "\tat org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)\n",
      "\tat org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)\n",
      "\tat org.apache.hadoop.examples.WordCount.main(WordCount.java:87)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:71)\n",
      "\tat org.apache.hadoop.util.ProgramDriver.run(ProgramDriver.java:144)\n",
      "\tat org.apache.hadoop.examples.ExampleDriver.main(ExampleDriver.java:74)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.util.RunJar.run(RunJar.java:244)\n",
      "\tat org.apache.hadoop.util.RunJar.main(RunJar.java:158)\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hadoop jar ${HADOOP_PATH}/share/hadoop/mapreduce/hadoop-mapreduce-examples-${HADOOP_VERSION}.jar  \\\n",
    "                               wordcount \\\n",
    "                               ./resources/examples/newyorknewyork.txt \\\n",
    "                               ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-r-00000  _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls ./output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And\t3\n",
      "Come\t1\n",
      "Head\t1\n",
      "I\t8\n",
      "I'll\t1\n",
      "I'm\t3\n",
      "If\t2\n",
      "In\t1\n",
      "It's\t1\n",
      "King\t1\n",
      "My\t1\n",
      "New\t13\n",
      "Right\t2\n",
      "Start\t1\n",
      "That\t2\n",
      "These\t2\n",
      "They\t3\n",
      "Top\t2\n",
      "York\t13\n",
      "You\t1\n",
      "a\t3\n",
      "about\t2\n",
      "all\t1\n",
      "am\t2\n",
      "anywhere\t2\n",
      "are\t3\n",
      "away\t2\n",
      "baby\t1\n",
      "be\t1\n",
      "bet\t1\n",
      "blues\t2\n",
      "brand\t2\n",
      "can\t2\n",
      "city\t2\n",
      "come\t1\n",
      "doesn't\t1\n",
      "find\t2\n",
      "gonna\t2\n",
      "have\t1\n",
      "heap\t2\n",
      "heart\t1\n",
      "hill\t3\n",
      "in\t3\n",
      "it\t8\n",
      "just\t1\n",
      "king\t2\n",
      "know\t1\n",
      "leaving\t1\n",
      "list\t1\n",
      "little\t2\n",
      "longing\t1\n",
      "make\t6\n",
      "melted\t1\n",
      "melting\t1\n",
      "never\t1\n",
      "new\t2\n",
      "news\t1\n",
      "of\t10\n",
      "old\t2\n",
      "on\t1\n",
      "part\t1\n",
      "shoes\t1\n",
      "sleep\t1\n",
      "sleeps\t1\n",
      "spreading\t1\n",
      "start\t2\n",
      "stray\t1\n",
      "that\t2\n",
      "the\t8\n",
      "there\t3\n",
      "through\t2\n",
      "to\t6\n",
      "today\t1\n",
      "town\t2\n",
      "up\t3\n",
      "vagabond\t1\n",
      "very\t1\n",
      "wake\t2\n",
      "want\t3\n",
      "you\t2\n"
     ]
    }
   ],
   "source": [
    "! cat ./output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Hadoop in Pseudo-Distributed Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting sshd server\n",
    "\n",
    "Check `/binder/postBuild` and `/resources/configs/ssh/sshd_config` files for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/sbin/sshd -f resources/configs/ssh/sshd_config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding names to know hosts \n",
    "\n",
    "Commands below stablish ssh connections to used host names/ips. This step avoids yes/no host confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added '[localhost]:8822' (ECDSA) to the list of known hosts.\n",
      "Warning: Permanently added '[0.0.0.0]:8822' (ECDSA) to the list of known hosts.\n"
     ]
    }
   ],
   "source": [
    "!ssh -o \"StrictHostKeyChecking no\" $USER@localhost -p 8822 -C \"exit\" \n",
    "!ssh -o \"StrictHostKeyChecking no\" $USER@0.0.0.0   -p 8822 -C \"exit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ssh options to Hadoop via envvar\n",
    "\n",
    "* connecting in a diferent port (`-p 8822`)\n",
    "* avoiding host key checking (`-o StrictHostKeyChecking=no`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HADOOP_SSH_OPTS=-o StrictHostKeyChecking=no -p 8822\n"
     ]
    }
   ],
   "source": [
    "%env HADOOP_SSH_OPTS= -o StrictHostKeyChecking=no -p 8822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PDSH_RCMD_TYPE=ssh\n"
     ]
    }
   ],
   "source": [
    "%env PDSH_RCMD_TYPE ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying configurations files to Hadoop folder\n",
    "\n",
    "Check the configuration files accordingly to the Hadoop version. \n",
    "Refer to the `/resources/configs/hadoop/<version>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/core-site.xml   ${HADOOP_PATH}/etc/hadoop/\n",
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/hdfs-site.xml   ${HADOOP_PATH}/etc/hadoop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Formatting the filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/07/07 17:38:30 INFO namenode.NameNode: STARTUP_MSG: \n",
      "/************************************************************\n",
      "STARTUP_MSG: Starting NameNode\n",
      "STARTUP_MSG:   host = a8a300d32d5a/172.17.0.2\n",
      "STARTUP_MSG:   args = [-format, -force, -nonInteractive]\n",
      "STARTUP_MSG:   version = 2.9.2\n",
      "STARTUP_MSG:   classpath = /home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/etc/hadoop:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/xmlenc-0.52.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/junit-4.11.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/activation-1.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-digester-1.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jersey-core-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jetty-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jettison-1.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-cli-1.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/guava-11.0.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jersey-json-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-lang-2.6.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/asm-3.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/gson-2.2.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/xz-1.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/hadoop-annotations-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/paranamer-2.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jsch-0.1.54.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jsp-api-2.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/log4j-1.2.17.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-codec-1.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/servlet-api-2.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/hadoop-auth-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/json-smart-1.3.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-io-2.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/avro-1.7.7.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/commons-net-3.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/jersey-server-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/hadoop-nfs-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/common/hadoop-common-2.9.2-tests.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/asm-3.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/hadoop-hdfs-client-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-2.9.2-tests.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-rbf-2.9.2-tests.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-native-client-2.9.2-tests.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-nfs-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/hdfs/hadoop-hdfs-client-2.9.2-tests.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/xmlenc-0.52.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/nimbus-jose-jwt-4.41.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/httpcore-4.4.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/activation-1.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-digester-1.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-i18n-2.0.0-M15.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/api-asn1-api-1.0.0-M20.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jettison-1.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-math3-3.1.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/guice-3.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/asm-3.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/gson-2.2.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jets3t-0.9.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jcip-annotations-1.0-1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/javax.inject-1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/xz-1.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-core-1.8.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/paranamer-2.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/curator-framework-2.7.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/htrace-core4-4.1.0-incubating.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/curator-recipes-2.7.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/api-util-1.0.0-M20.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jsch-0.1.54.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jsp-api-2.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/httpclient-4.5.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-lang3-3.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-beanutils-1.7.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jetty-sslengine-6.1.26.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/curator-client-2.7.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/stax2-api-3.1.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-configuration-1.6.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/fst-2.50.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/json-smart-1.3.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/woodstox-core-5.0.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/avro-1.7.7.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/commons-net-3.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/snappy-java-1.0.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/lib/java-xmlbuilder-0.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-common-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-router-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-tests-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-common-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-client-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-api-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-registry-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/hadoop-annotations-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/avro-1.7.7.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/snappy-java-1.0.5.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2-tests.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar:/home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.9.2.jar:/contrib/capacity-scheduler/*.jar\n",
      "STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 826afbeae31ca687bc2f8471dc841b66ed2c6704; compiled by 'ajisaka' on 2018-11-13T12:42Z\n",
      "STARTUP_MSG:   java = 1.8.0_212\n",
      "************************************************************/\n",
      "19/07/07 17:38:30 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\n",
      "19/07/07 17:38:30 INFO namenode.NameNode: createNameNode [-format, -force, -nonInteractive]\n",
      "Formatting using clusterid: CID-dc4aa962-4875-4028-b249-539f02312aaa\n",
      "19/07/07 17:38:30 INFO namenode.FSEditLog: Edit logging is async:true\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: KeyProvider: null\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: fsLock is fair: true\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: fsOwner             = matheus (auth:SIMPLE)\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: supergroup          = supergroup\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: isPermissionEnabled = true\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: HA Enabled: false\n",
      "19/07/07 17:38:30 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\n",
      "19/07/07 17:38:30 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\n",
      "19/07/07 17:38:30 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: The block deletion will start around 2019 Jul 07 17:38:30\n",
      "19/07/07 17:38:30 INFO util.GSet: Computing capacity for map BlocksMap\n",
      "19/07/07 17:38:30 INFO util.GSet: VM type       = 64-bit\n",
      "19/07/07 17:38:30 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB\n",
      "19/07/07 17:38:30 INFO util.GSet: capacity      = 2^21 = 2097152 entries\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false\n",
      "19/07/07 17:38:30 WARN conf.Configuration: No unit for dfs.heartbeat.interval(3) assuming SECONDS\n",
      "19/07/07 17:38:30 WARN conf.Configuration: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: defaultReplication         = 1\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: maxReplication             = 512\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: minReplication             = 1\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\n",
      "19/07/07 17:38:30 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: Append Enabled: true\n",
      "19/07/07 17:38:30 INFO namenode.FSDirectory: GLOBAL serial map: bits=24 maxEntries=16777215\n",
      "19/07/07 17:38:30 INFO util.GSet: Computing capacity for map INodeMap\n",
      "19/07/07 17:38:30 INFO util.GSet: VM type       = 64-bit\n",
      "19/07/07 17:38:30 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB\n",
      "19/07/07 17:38:30 INFO util.GSet: capacity      = 2^20 = 1048576 entries\n",
      "19/07/07 17:38:30 INFO namenode.FSDirectory: ACLs enabled? false\n",
      "19/07/07 17:38:30 INFO namenode.FSDirectory: XAttrs enabled? true\n",
      "19/07/07 17:38:30 INFO namenode.NameNode: Caching file names occurring more than 10 times\n",
      "19/07/07 17:38:30 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: falseskipCaptureAccessTimeOnlyChange: false\n",
      "19/07/07 17:38:30 INFO util.GSet: Computing capacity for map cachedBlocks\n",
      "19/07/07 17:38:30 INFO util.GSet: VM type       = 64-bit\n",
      "19/07/07 17:38:30 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB\n",
      "19/07/07 17:38:30 INFO util.GSet: capacity      = 2^18 = 262144 entries\n",
      "19/07/07 17:38:30 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\n",
      "19/07/07 17:38:30 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\n",
      "19/07/07 17:38:30 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\n",
      "19/07/07 17:38:30 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\n",
      "19/07/07 17:38:30 INFO util.GSet: Computing capacity for map NameNodeRetryCache\n",
      "19/07/07 17:38:30 INFO util.GSet: VM type       = 64-bit\n",
      "19/07/07 17:38:30 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB\n",
      "19/07/07 17:38:30 INFO util.GSet: capacity      = 2^15 = 32768 entries\n",
      "19/07/07 17:38:30 INFO namenode.FSImage: Allocated new BlockPoolId: BP-380199889-172.17.0.2-1562521110634\n",
      "19/07/07 17:38:30 INFO common.Storage: Storage directory /tmp/hadoop-matheus/dfs/name has been successfully formatted.\n",
      "19/07/07 17:38:30 INFO namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-matheus/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression\n",
      "19/07/07 17:38:30 INFO namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-matheus/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 326 bytes saved in 0 seconds .\n",
      "19/07/07 17:38:30 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\n",
      "19/07/07 17:38:30 INFO namenode.NameNode: SHUTDOWN_MSG: \n",
      "/************************************************************\n",
      "SHUTDOWN_MSG: Shutting down NameNode at a8a300d32d5a/172.17.0.2\n",
      "************************************************************/\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs namenode -format -force -nonInteractive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting DFS (NameNode, SecondaryNameNode, and DataNode daemons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting namenodes on [localhost]\n",
      "localhost: starting namenode, logging to /home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/logs/hadoop-matheus-namenode-a8a300d32d5a.out\n",
      "localhost: starting datanode, logging to /home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/logs/hadoop-matheus-datanode-a8a300d32d5a.out\n",
      "Starting secondary namenodes [0.0.0.0]\n",
      "0.0.0.0: starting secondarynamenode, logging to /home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/logs/hadoop-matheus-secondarynamenode-a8a300d32d5a.out\n",
      "689 Jps\n",
      "562 SecondaryNameNode\n",
      "397 DataNode\n",
      "271 NameNode\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/sbin/start-dfs.sh\n",
    "!jps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## MapReduce - Word count example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating folders in the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/\n",
    "!${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/matheus/\n",
    "!${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/matheus/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying a file to a folder in the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -put ./resources/examples/newyorknewyork.txt /user/matheus/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in a folder of the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 matheus supergroup        865 2019-07-07 17:38 /user/matheus/input/newyorknewyork.txt\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -ls /user/matheus/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the contents of a file in the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start spreading the news\n",
      "I am leaving today\n",
      "I want to be a part of it\n",
      "New York New York\n",
      "These vagabond shoes\n",
      "They are longing to stray\n",
      "Right through the very heart of it\n",
      "New York New York\n",
      "I want to wake up in that city\n",
      "That doesn't sleep\n",
      "And find I'm king of the hill\n",
      "Top of the heap\n",
      "My little town blues\n",
      "They are melting away\n",
      "I gonna make a brand new start of it\n",
      "In old New York\n",
      "If I can make it there\n",
      "I'll make it anywhere\n",
      "It's up to you\n",
      "New York New York\n",
      "New York New York\n",
      "I want to wake up in that city\n",
      "That never sleeps\n",
      "And find I'm king of the hill\n",
      "Top of the list\n",
      "Head of the heap\n",
      "King of the hill\n",
      "These are little town blues\n",
      "They have all melted away\n",
      "I am about to make a brand new start of it\n",
      "Right there in old New York\n",
      "And you bet baby\n",
      "If I can make it there\n",
      "You know I'm gonna make it just about anywhere\n",
      "Come on come through\n",
      "New York New York New York\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -cat /user/matheus/input/newyorknewyork.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Running MapReduce job in Pseudo-Distributed Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/07/07 17:39:04 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "19/07/07 17:39:04 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "19/07/07 17:39:04 INFO input.FileInputFormat: Total input files to process : 1\n",
      "19/07/07 17:39:04 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "19/07/07 17:39:05 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2007366941_0001\n",
      "19/07/07 17:39:05 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "19/07/07 17:39:05 INFO mapreduce.Job: Running job: job_local2007366941_0001\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "19/07/07 17:39:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/07/07 17:39:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: Starting task: attempt_local2007366941_0001_m_000000_0\n",
      "19/07/07 17:39:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/07/07 17:39:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/07/07 17:39:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: Processing split: hdfs://localhost:9000/user/matheus/input/newyorknewyork.txt:0+865\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: soft limit at 83886080\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: \n",
      "19/07/07 17:39:05 INFO mapred.MapTask: Starting flush of map output\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: Spilling map output\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: bufstart = 0; bufend = 1625; bufvoid = 104857600\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213640(104854560); length = 757/6553600\n",
      "19/07/07 17:39:05 INFO mapred.MapTask: Finished spill 0\n",
      "19/07/07 17:39:05 INFO mapred.Task: Task:attempt_local2007366941_0001_m_000000_0 is done. And is in the process of committing\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: map\n",
      "19/07/07 17:39:05 INFO mapred.Task: Task 'attempt_local2007366941_0001_m_000000_0' done.\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local2007366941_0001_m_000000_0\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: Starting task: attempt_local2007366941_0001_r_000000_0\n",
      "19/07/07 17:39:05 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1\n",
      "19/07/07 17:39:05 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "19/07/07 17:39:05 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "19/07/07 17:39:05 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5c46928b\n",
      "19/07/07 17:39:05 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=334338464, maxSingleShuffleLimit=83584616, mergeThreshold=220663392, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "19/07/07 17:39:05 INFO reduce.EventFetcher: attempt_local2007366941_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "19/07/07 17:39:05 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2007366941_0001_m_000000_0 decomp: 890 len: 894 to MEMORY\n",
      "19/07/07 17:39:05 INFO reduce.InMemoryMapOutput: Read 890 bytes from map-output for attempt_local2007366941_0001_m_000000_0\n",
      "19/07/07 17:39:05 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 890, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->890\n",
      "19/07/07 17:39:05 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "19/07/07 17:39:05 WARN io.ReadaheadPool: Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "19/07/07 17:39:05 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "19/07/07 17:39:05 INFO mapred.Merger: Merging 1 sorted segments\n",
      "19/07/07 17:39:05 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 884 bytes\n",
      "19/07/07 17:39:05 INFO reduce.MergeManagerImpl: Merged 1 segments, 890 bytes to disk to satisfy reduce memory limit\n",
      "19/07/07 17:39:05 INFO reduce.MergeManagerImpl: Merging 1 files, 894 bytes from disk\n",
      "19/07/07 17:39:05 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "19/07/07 17:39:05 INFO mapred.Merger: Merging 1 sorted segments\n",
      "19/07/07 17:39:05 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 884 bytes\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "19/07/07 17:39:05 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "19/07/07 17:39:05 INFO mapred.Task: Task:attempt_local2007366941_0001_r_000000_0 is done. And is in the process of committing\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "19/07/07 17:39:05 INFO mapred.Task: Task attempt_local2007366941_0001_r_000000_0 is allowed to commit now\n",
      "19/07/07 17:39:05 INFO output.FileOutputCommitter: Saved output of task 'attempt_local2007366941_0001_r_000000_0' to hdfs://localhost:9000/user/matheus/output/_temporary/0/task_local2007366941_0001_r_000000\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "19/07/07 17:39:05 INFO mapred.Task: Task 'attempt_local2007366941_0001_r_000000_0' done.\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: Finishing task: attempt_local2007366941_0001_r_000000_0\n",
      "19/07/07 17:39:05 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "19/07/07 17:39:06 INFO mapreduce.Job: Job job_local2007366941_0001 running in uber mode : false\n",
      "19/07/07 17:39:06 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/07/07 17:39:06 INFO mapreduce.Job: Job job_local2007366941_0001 completed successfully\n",
      "19/07/07 17:39:06 INFO mapreduce.Job: Counters: 35\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=608832\n",
      "\t\tFILE: Number of bytes written=1554674\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=1730\n",
      "\t\tHDFS: Number of bytes written=571\n",
      "\t\tHDFS: Number of read operations=13\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=4\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=36\n",
      "\t\tMap output records=190\n",
      "\t\tMap output bytes=1625\n",
      "\t\tMap output materialized bytes=894\n",
      "\t\tInput split bytes=124\n",
      "\t\tCombine input records=190\n",
      "\t\tCombine output records=80\n",
      "\t\tReduce input groups=80\n",
      "\t\tReduce shuffle bytes=894\n",
      "\t\tReduce input records=80\n",
      "\t\tReduce output records=80\n",
      "\t\tSpilled Records=160\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=4\n",
      "\t\tTotal committed heap usage (bytes)=611319808\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=865\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=571\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hadoop jar  ./${HADOOP_PATH}/share/hadoop/mapreduce/hadoop-mapreduce-examples-${HADOOP_VERSION}.jar wordcount \\\n",
    "                                /user/matheus/input /user/matheus/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 matheus supergroup          0 2019-07-07 17:39 /user/matheus/output/_SUCCESS\n",
      "-rw-r--r--   1 matheus supergroup        571 2019-07-07 17:39 /user/matheus/output/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -ls /user/matheus/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And\t3\n",
      "Come\t1\n",
      "Head\t1\n",
      "I\t8\n",
      "I'll\t1\n",
      "I'm\t3\n",
      "If\t2\n",
      "In\t1\n",
      "It's\t1\n",
      "King\t1\n",
      "My\t1\n",
      "New\t13\n",
      "Right\t2\n",
      "Start\t1\n",
      "That\t2\n",
      "These\t2\n",
      "They\t3\n",
      "Top\t2\n",
      "York\t13\n",
      "You\t1\n",
      "a\t3\n",
      "about\t2\n",
      "all\t1\n",
      "am\t2\n",
      "anywhere\t2\n",
      "are\t3\n",
      "away\t2\n",
      "baby\t1\n",
      "be\t1\n",
      "bet\t1\n",
      "blues\t2\n",
      "brand\t2\n",
      "can\t2\n",
      "city\t2\n",
      "come\t1\n",
      "doesn't\t1\n",
      "find\t2\n",
      "gonna\t2\n",
      "have\t1\n",
      "heap\t2\n",
      "heart\t1\n",
      "hill\t3\n",
      "in\t3\n",
      "it\t8\n",
      "just\t1\n",
      "king\t2\n",
      "know\t1\n",
      "leaving\t1\n",
      "list\t1\n",
      "little\t2\n",
      "longing\t1\n",
      "make\t6\n",
      "melted\t1\n",
      "melting\t1\n",
      "never\t1\n",
      "new\t2\n",
      "news\t1\n",
      "of\t10\n",
      "old\t2\n",
      "on\t1\n",
      "part\t1\n",
      "shoes\t1\n",
      "sleep\t1\n",
      "sleeps\t1\n",
      "spreading\t1\n",
      "start\t2\n",
      "stray\t1\n",
      "that\t2\n",
      "the\t8\n",
      "there\t3\n",
      "through\t2\n",
      "to\t6\n",
      "today\t1\n",
      "town\t2\n",
      "up\t3\n",
      "vagabond\t1\n",
      "very\t1\n",
      "wake\t2\n",
      "want\t3\n",
      "you\t2\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -cat /user/matheus/output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Starting YARN in Pseudo-Distributed Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying configurations files to Hadoop folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/mapred-site.xml ${HADOOP_PATH}/etc/hadoop/\n",
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/yarn-site.xml   ${HADOOP_PATH}/etc/hadoop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting YARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting yarn daemons\n",
      "starting resourcemanager, logging to /home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/logs/yarn-matheus-resourcemanager-a8a300d32d5a.out\n",
      "localhost: starting nodemanager, logging to /home/matheus/local-home/git/github/binderhub-hadoop/hadoop-2.9.2/logs/yarn-matheus-nodemanager-a8a300d32d5a.out\n",
      "562 SecondaryNameNode\n",
      "1170 ResourceManager\n",
      "1509 Jps\n",
      "397 DataNode\n",
      "1390 NodeManager\n",
      "271 NameNode\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/sbin/start-yarn.sh\n",
    "!jps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## MapReduce via YARN - Word count example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/07/07 17:39:24 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "19/07/07 17:39:24 INFO input.FileInputFormat: Total input files to process : 1\n",
      "19/07/07 17:39:25 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "19/07/07 17:39:25 INFO Configuration.deprecation: yarn.resourcemanager.system-metrics-publisher.enabled is deprecated. Instead, use yarn.system-metrics-publisher.enabled\n",
      "19/07/07 17:39:25 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1562521158478_0001\n",
      "19/07/07 17:39:26 INFO impl.YarnClientImpl: Submitted application application_1562521158478_0001\n",
      "19/07/07 17:39:26 INFO mapreduce.Job: The url to track the job: http://a8a300d32d5a:8088/proxy/application_1562521158478_0001/\n",
      "19/07/07 17:39:26 INFO mapreduce.Job: Running job: job_1562521158478_0001\n",
      "19/07/07 17:39:33 INFO mapreduce.Job: Job job_1562521158478_0001 running in uber mode : false\n",
      "19/07/07 17:39:33 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "19/07/07 17:39:36 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "19/07/07 17:39:40 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "19/07/07 17:39:41 INFO mapreduce.Job: Job job_1562521158478_0001 completed successfully\n",
      "19/07/07 17:39:41 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=894\n",
      "\t\tFILE: Number of bytes written=398631\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=989\n",
      "\t\tHDFS: Number of bytes written=571\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=1711\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1771\n",
      "\t\tTotal time spent by all map tasks (ms)=1711\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1771\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=1711\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1771\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=1752064\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1813504\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=36\n",
      "\t\tMap output records=190\n",
      "\t\tMap output bytes=1625\n",
      "\t\tMap output materialized bytes=894\n",
      "\t\tInput split bytes=124\n",
      "\t\tCombine input records=190\n",
      "\t\tCombine output records=80\n",
      "\t\tReduce input groups=80\n",
      "\t\tReduce shuffle bytes=894\n",
      "\t\tReduce input records=80\n",
      "\t\tReduce output records=80\n",
      "\t\tSpilled Records=160\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=88\n",
      "\t\tCPU time spent (ms)=670\n",
      "\t\tPhysical memory (bytes) snapshot=487591936\n",
      "\t\tVirtual memory (bytes) snapshot=3946115072\n",
      "\t\tTotal committed heap usage (bytes)=347602944\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=865\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=571\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/yarn jar  ./${HADOOP_PATH}/share/hadoop/mapreduce/hadoop-mapreduce-examples-${HADOOP_VERSION}.jar wordcount \\\n",
    "                                /user/matheus/input /user/matheus/output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 matheus supergroup          0 2019-07-07 17:39 /user/matheus/output2/_SUCCESS\n",
      "-rw-r--r--   1 matheus supergroup        571 2019-07-07 17:39 /user/matheus/output2/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -ls /user/matheus/output2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Reading output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And\t3\n",
      "Come\t1\n",
      "Head\t1\n",
      "I\t8\n",
      "I'll\t1\n",
      "I'm\t3\n",
      "If\t2\n",
      "In\t1\n",
      "It's\t1\n",
      "King\t1\n",
      "My\t1\n",
      "New\t13\n",
      "Right\t2\n",
      "Start\t1\n",
      "That\t2\n",
      "These\t2\n",
      "They\t3\n",
      "Top\t2\n",
      "York\t13\n",
      "You\t1\n",
      "a\t3\n",
      "about\t2\n",
      "all\t1\n",
      "am\t2\n",
      "anywhere\t2\n",
      "are\t3\n",
      "away\t2\n",
      "baby\t1\n",
      "be\t1\n",
      "bet\t1\n",
      "blues\t2\n",
      "brand\t2\n",
      "can\t2\n",
      "city\t2\n",
      "come\t1\n",
      "doesn't\t1\n",
      "find\t2\n",
      "gonna\t2\n",
      "have\t1\n",
      "heap\t2\n",
      "heart\t1\n",
      "hill\t3\n",
      "in\t3\n",
      "it\t8\n",
      "just\t1\n",
      "king\t2\n",
      "know\t1\n",
      "leaving\t1\n",
      "list\t1\n",
      "little\t2\n",
      "longing\t1\n",
      "make\t6\n",
      "melted\t1\n",
      "melting\t1\n",
      "never\t1\n",
      "new\t2\n",
      "news\t1\n",
      "of\t10\n",
      "old\t2\n",
      "on\t1\n",
      "part\t1\n",
      "shoes\t1\n",
      "sleep\t1\n",
      "sleeps\t1\n",
      "spreading\t1\n",
      "start\t2\n",
      "stray\t1\n",
      "that\t2\n",
      "the\t8\n",
      "there\t3\n",
      "through\t2\n",
      "to\t6\n",
      "today\t1\n",
      "town\t2\n",
      "up\t3\n",
      "vagabond\t1\n",
      "very\t1\n",
      "wake\t2\n",
      "want\t3\n",
      "you\t2\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -cat /user/matheus/output2/part-r-00000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
